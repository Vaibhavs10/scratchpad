{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPKxLsB6DAC4TMsGPiXuGW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaibhavs10/scratchpad/blob/main/streaming_tts_repro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHou9Lnf79jo",
        "outputId": "38898ee1-b4d4-4fbb-e56b-8dc1f586c427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/coqui-ai/tts.git@9175a4d8d85815e24956e22aa76590f96e2815d9 deepspeed==0.8.3 gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from TTS.api import TTS\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "from TTS.utils.generic_utils import get_user_data_dir\n",
        "\n",
        "import gradio as gr\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "os.environ[\"COQUI_TOS_AGREED\"] = \"1\"\n",
        "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v1\")\n",
        "\n",
        "model_path = os.path.join(get_user_data_dir(\"tts\"), \"tts_models--multilingual--multi-dataset--xtts_v1\")\n",
        "config = XttsConfig()\n",
        "config.load_json(os.path.join(model_path, \"config.json\"))\n",
        "model = Xtts.init_from_config(config)\n",
        "model.load_checkpoint(\n",
        "    config,\n",
        "    checkpoint_path=os.path.join(model_path, \"model.pth\"),\n",
        "    vocab_path=os.path.join(model_path, \"vocab.json\"),\n",
        "    eval=True,\n",
        "    use_deepspeed=True\n",
        ")\n",
        "model.cuda()\n",
        "\n",
        "def stream_audio(synthesis_text):\n",
        "    gpt_cond_latent, _, speaker_embedding = model.get_conditioning_latents(audio_path=\"female.wav\")\n",
        "    wav_chunks = []\n",
        "\n",
        "    chunks = model.inference_stream(\n",
        "        synthesis_text,\n",
        "        \"en\",\n",
        "        gpt_cond_latent,\n",
        "        speaker_embedding)\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        print(f\"Received chunk {i} of audio length {chunk.shape[-1]}\")\n",
        "        bytes_wav = bytes()\n",
        "        byte_io = io.BytesIO(bytes_wav)\n",
        "        write(byte_io, 24000, chunk.detach().cpu().numpy().squeeze())\n",
        "        result_bytes = byte_io.read()\n",
        "        yield result_bytes\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=stream_audio,\n",
        "    inputs=gr.Textbox(),\n",
        "    outputs=gr.Audio(autoplay=True, streaming=True),\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.queue().launch(debug=True)"
      ],
      "metadata": {
        "id": "GhT--VstZx5C",
        "outputId": "cbacc97f-a096-44dc-b9c4-f4f10700b64a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > tts_models/multilingual/multi-dataset/xtts_v1 is already downloaded.\n",
            " > Using model: xtts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ecQEkqGbNz1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}