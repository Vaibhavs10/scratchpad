{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPDo5Wt/newtt7whdouE3a8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaibhavs10/scratchpad/blob/main/streaming_tts_repro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHou9Lnf79jo",
        "outputId": "38898ee1-b4d4-4fbb-e56b-8dc1f586c427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/coqui-ai/tts.git@9175a4d8d85815e24956e22aa76590f96e2815d9 deepspeed==0.8.3 gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from TTS.api import TTS\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "from TTS.utils.generic_utils import get_user_data_dir\n",
        "\n",
        "os.environ[\"COQUI_TOS_AGREED\"] = \"1\"\n",
        "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v1\")\n",
        "\n",
        "model_path = os.path.join(get_user_data_dir(\"tts\"), \"tts_models--multilingual--multi-dataset--xtts_v1\")\n",
        "config = XttsConfig()\n",
        "config.load_json(os.path.join(model_path, \"config.json\"))\n",
        "model = Xtts.init_from_config(config)\n",
        "model.load_checkpoint(\n",
        "    config,\n",
        "    checkpoint_path=os.path.join(model_path, \"model.pth\"),\n",
        "    vocab_path=os.path.join(model_path, \"vocab.json\"),\n",
        "    eval=True,\n",
        "    use_deepspeed=True\n",
        ")\n",
        "model.cuda()\n",
        "\n",
        "gpt_cond_latent, _, speaker_embedding = model.get_conditioning_latents(audio_path=\"female.wav\")\n",
        "wav_chuncks = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "kNJCi0Sb-hXt",
        "outputId": "d400541b-87a4-43cc-c8f0-1a53990715a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d858d0c13206>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_user_data_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tts_models--multilingual--multi-dataset--xtts_v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXttsConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m model.load_checkpoint(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/coqpit/coqpit.py\u001b[0m in \u001b[0;36mload_json\u001b[0;34m(self, file_name)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0mCoqpit\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mCoqpit\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \"\"\"\n\u001b[0;32m--> 726\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m             \u001b[0minput_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mdump_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v1/config.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = model.inference_stream(\n",
        "    \"It took me quite a long time to develop a voice and now that I have it I am not going to be silent.\",\n",
        "    \"en\",\n",
        "    gpt_cond_latent,\n",
        "    speaker_embedding\n",
        ")\n",
        "\n",
        "for i, chunk in enumerate(chunks):\n",
        "    wav_chuncks.append(chunk)\n",
        "    print(f\"Received chunk {i} of audio length {chunk.shape[-1]}\")\n",
        "wav = torch.cat(wav_chuncks, dim=0)\n",
        "torchaudio.save(\"xtts_streaming.wav\", wav.squeeze().unsqueeze(0).cpu(), 24000)"
      ],
      "metadata": {
        "id": "0cplpco-Ds6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio app test"
      ],
      "metadata": {
        "id": "fPsxfOdQd5CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from TTS.api import TTS\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "from TTS.utils.generic_utils import get_user_data_dir\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "os.environ[\"COQUI_TOS_AGREED\"] = \"1\"\n",
        "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v1\")\n",
        "\n",
        "model_path = os.path.join(get_user_data_dir(\"tts\"), \"tts_models--multilingual--multi-dataset--xtts_v1\")\n",
        "config = XttsConfig()\n",
        "config.load_json(os.path.join(model_path, \"config.json\"))\n",
        "model = Xtts.init_from_config(config)\n",
        "model.load_checkpoint(\n",
        "    config,\n",
        "    checkpoint_path=os.path.join(model_path, \"model.pth\"),\n",
        "    vocab_path=os.path.join(model_path, \"vocab.json\"),\n",
        "    eval=True,\n",
        "    use_deepspeed=True\n",
        ")\n",
        "model.cuda()\n",
        "\n",
        "def stream_audio(synthesis_text):\n",
        "    gpt_cond_latent, _, speaker_embedding = model.get_conditioning_latents(audio_path=\"female.wav\")\n",
        "    wav_chunks = []\n",
        "\n",
        "    chunks = model.inference_stream(\n",
        "        synthesis_text,\n",
        "        \"en\",\n",
        "        gpt_cond_latent,\n",
        "        speaker_embedding)\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        wav_chunks.append(chunk)\n",
        "        print(f\"Received chunk {i} of audio length {chunk.shape[-1]}\")\n",
        "        yield chunk.detach().cpu().numpy().squeeze()\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=stream_audio,\n",
        "    inputs=gr.Textbox(),\n",
        "    outputs=gr.Audio(autoplay=True, streaming=True),\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.queue().launch(debug=True)"
      ],
      "metadata": {
        "id": "GhT--VstZx5C",
        "outputId": "cbacc97f-a096-44dc-b9c4-f4f10700b64a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > tts_models/multilingual/multi-dataset/xtts_v1 is already downloaded.\n",
            " > Using model: xtts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ecQEkqGbNz1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}